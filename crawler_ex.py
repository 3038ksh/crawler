import requestsfrom bs4 import BeautifulSoupdef crawl(url):    # 코드 긁어오기    source_code = requests.get(url)    # 텍스트로 바꾸기    plain_text = source_code.text    # 파싱    soup = BeautifulSoup(plain_text, "lxml")    # 원하는 데이터 리스트 만들기    item_list = soup.find_all("div", attrs={"class":"items-wrapper"})    # 만약 Dewey class no가 없을 경우 LC classification 저장용    ret_str = ""    for item in item_list:        # 원하는 데이터 또 찾기        item_h3 = item.find_all('h3')        for h3 in item_h3:            # Dewey 찾기            if h3.text == "Dewey class no.":                # print(item.find("span", attrs={"dir":"ltr"}).text)                return item.find("span", attrs={"dir":"ltr"}).text            # LC classification 찾기            if h3.text == "LC classification":                # print(item.find("span", attrs={"dir": "ltr"}).text)                ret_str = item.find("span", attrs={"dir":"ltr"}).text    return ret_strcrawl("https://catalog.loc.gov/vwebv/search?searchArg1=9780817682675&argType1=all&searchCode1=GKEY&searchType=2&combine2=and&searchArg2=&argType2=all&searchCode2=GKEY&combine3=and&searchArg3=&argType3=all&searchCode3=GKEY&year=1517-2017&fromYear=&toYear=&location=all&place=all&type=all&language=all&recCount=25")